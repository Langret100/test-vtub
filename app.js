// GitHub Pages fix:
// three-vrm imports 'three' as a bare module specifier.
// We provide an importmap in index.html, so we can import from 'three' here too.
import * as THREE from 'three';
import { OrbitControls } from 'three/addons/controls/OrbitControls.js';
import { GLTFLoader } from 'three/addons/loaders/GLTFLoader.js';
// IMPORTANT: three-vrm v2 can be incompatible with newer Three.js shader chunks (r157+),
// and may cause MToon shader compile errors (e.g. "GeometricContext").
// Use a recent three-vrm v3.x build that tracks newer Three.js revisions.
import { VRMLoaderPlugin, VRMUtils } from 'https://cdn.jsdelivr.net/npm/@pixiv/three-vrm@3.4.5/lib/three-vrm.module.js';
import { VRMAnimationLoaderPlugin, createVRMAnimationClip } from 'https://cdn.jsdelivr.net/npm/@pixiv/three-vrm-animation@3.4.5/lib/three-vrm-animation.module.js';

const canvas = document.getElementById('c');
const logEl = document.getElementById('log');
const form = document.getElementById('form');
const msgInput = document.getElementById('msg');
const pitchEl = document.getElementById('pitch');
const rateEl = document.getElementById('rate');
const stopBtn = document.getElementById('stopBtn');

// ---------------------------
// Chat helpers
// ---------------------------
function addMessage(who, text) {
  const el = document.createElement('div');
  el.className = `msg ${who}`;
  const whoLabel = document.createElement('span');
  whoLabel.className = 'who';
  whoLabel.textContent = who === 'user' ? 'You' : 'VTuber';
  const body = document.createElement('div');
  body.textContent = text;
  el.appendChild(whoLabel);
  el.appendChild(body);
  logEl.appendChild(el);
  logEl.scrollTop = logEl.scrollHeight;
}

// Very simple â€œVTuber-likeâ€ reply (demo).
function pick(arr) {
  return arr[Math.floor(Math.random() * arr.length)];
}

function norm(s) {
  return (s || '').trim();
}

function makeReply(userText) {
  const t = norm(userText);
  if (!t) return 'ì‘? ë‹¤ì‹œ í•œ ë²ˆ ë§í•´ì¤„ëž˜?';

  // Greetings / small talk
  if (/^(ì•ˆë…•|ã…Žã…‡|í•˜ì´|hello|hi)\b/i.test(t)) {
    return pick([
      'ì•ˆë…•! ì˜¤ëŠ˜ ê¸°ë¶„ ì–´ë•Œ? ðŸ˜Š',
      'í•˜ì´í•˜ì´~ ë‚˜ ì™”ì–´! ë­ í• ê¹Œ?',
      'ì•ˆë‡½! ë§Œë‚˜ì„œ ë°˜ê°€ì›Œ~',
    ]);
  }
  if (/(ê³ ë§ˆì›Œ|thanks|thx)/i.test(t)) {
    return pick(['ì—í—¤í—¤~ ì²œë§Œì—!', 'ë³„ë§ì„~ ë„ì›€ì´ ë˜ë©´ ë‚˜ë„ ì¢‹ì•„!', 'ì–¸ì œë“ ì§€ ë¶ˆëŸ¬ì¤˜!']);
  }
  if (/(ë¯¸ì•ˆ|sorry)/i.test(t)) {
    return pick(['ê´œì°®ì•„ ê´œì°®ì•„~', 'ì—ì´ ê´œì°®ì§€!', 'ì‹ ê²½ ì“°ì§€ ë§ˆ~']);
  }
  if (/(í”¼ê³¤|ì¡¸ë ¤|ìž |sleep)/i.test(t)) {
    return pick(['ìœ¼ì•™â€¦ ë‚˜ë„ ì‚´ì§ ì¡¸ë ¤â€¦ ê°™ì´ ì‰¬ì—ˆë‹¤ í• ê¹Œ?', 'ë”°ëœ»í•œ ë¬¼ í•œ ìž” ì–´ë•Œ?', 'ìž ê¹ ìŠ¤íŠ¸ë ˆì¹­í•˜ê³  ì˜¬ëž˜?']);
  }

  // Identity / playful
  if (/(ì´ë¦„|ëˆ„êµ¬|ì •ì²´|ëˆ„êµ¬ì•¼|who are you)/i.test(t)) {
    return pick([
      'ë‚˜ëŠ” ë°ëª¨ VTuberì•¼! ì•„ì§ì€ ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜ì´ì§€ë§Œ, ì ì  ë˜‘ë˜‘í•´ì§ˆì§€ë„? ðŸ˜š',
      'ë‚˜ëŠ” êµì‹¤ì— ì‚¬ëŠ”(?) ìž‘ì€ VTuber~ íŽ¸í•˜ê²Œ ë¶ˆëŸ¬ì¤˜!',
    ]);
  }
  if (/(ì‚¬ëž‘|ì¢‹ì•„í•´|ë³´ê³ ì‹¶|love you)/i.test(t)) {
    return pick([
      'ì—ì—£â€¦ ê°‘ìžê¸° ê·¸ëŸ° ë§ í•˜ë©´ ë¶€ë„ëŸ½ìž–ì•„â€¦ ðŸ˜³',
      'ë‚˜ë„ ë„ˆ ì¢‹ì•„~! (ì†Œê³¤ì†Œê³¤) ðŸ¤',
      'ìœ¼ì•„ì•„â€¦ ì‹¬ìž¥ ë‘ê·¼â€¦!',
    ]);
  }
  if (/(ë°°ê³ |ë°¥|ë¨¹ì„|ê°„ì‹|ì¹˜í‚¨|ë–¡ë³¶ì´)/i.test(t)) {
    return pick([
      'ê°„ì‹ íƒ€ìž„! ë­ ë¨¹ê³  ì‹¶ì–´? ë‚œ ë‹¬ë‹¬í•œ ê±° ë•¡ê²¨~',
      'ë°°ê³ í”„ë©´ ì§‘ì¤‘ ì•ˆ ë¼! ê°™ì´ ë­ ì£¼ì›Œë¨¹ìž ðŸ˜‹',
      'ì¹˜í‚¨â€¦? ë‚˜ë„ í•œ ìž…ë§Œâ€¦!',
    ]);
  }
  if (/(ê³µë¶€|ìˆ™ì œ|ì‹œí—˜|ê³¼ì œ)/i.test(t)) {
    return pick([
      'ê³µë¶€ëŠ” ì‹«ì§€ë§Œâ€¦ ê°™ì´ í•˜ë©´ í•  ë§Œí•´! 25ë¶„ ì§‘ì¤‘í•˜ê³  5ë¶„ ì‰¬ìž!',
      'ì˜¤ì¼€ì´, ì˜¤ëŠ˜ ëª©í‘œ ë”± í•˜ë‚˜ë§Œ ì •í•´ë³¼ëž˜?',
      'ì‹œí—˜ì´ë©´ ì»¨ë””ì…˜ì´ ì œì¼ ì¤‘ìš”í•´. ë¬¼ ë§ˆì‹œê³ ! ðŸ˜¤',
    ]);
  }

  // Simple â€œopinionsâ€
  if (/[?ï¼Ÿ]$/.test(t) || /(ì™œ|ì–´ë–»ê²Œ|ë­ì•¼|ì–´ë–¤)/.test(t)) {
    return pick([
      'ìŒâ€¦ ë‚´ ìƒê°ì—” ì´ë ‡ê²Œ í•´ë³´ëŠ” ê²Œ ì¢‹ì„ ê²ƒ ê°™ì•„!',
      'ê·¸ê±° ì¢‹ì€ ì§ˆë¬¸ì´ì•¼. í•œ ë²ˆ ê°™ì´ ì •ë¦¬í•´ë³¼ê¹Œ?',
      'ìž ê¹ë§Œâ€¦ ë¨¸ë¦¬ êµ´ë¦¬ëŠ” ì¤‘â€¦ ðŸ˜³',
    ]);
  }

  if (/(ã…‹ã…‹|ã…Žã…Ž|lol|ê·€ì—½|ì›ƒê²¨)/i.test(t)) {
    return pick(['ã…‹ã…‹ã…‹ ê·¸ì¹˜? ë‚˜ë„ ì›ƒê²¨!', 'ì—í—¤í—¤~ ë‚˜ë„ ë¹µ í„°ì¡Œì–´!', 'ì•— ë¶€ë„ëŸ½ë‹¤â€¦']);
  }

  // Fallback
  const echo = t.length > 24 ? t.slice(0, 24) + 'â€¦' : t;
  return pick([
    `ì‘ì‘, â€œ${echo}â€ ë§žì§€? ë‚˜ë„ ê·¸ë ‡ê²Œ ëŠê»´! ê·¸ëŸ¼ ë„ˆëŠ” ì–´ë–¤ ì ì´ ì œì¼ ë§ˆìŒì— ë“¤ì–´?`,
    `ì˜¤ì¼€ì´! â€œ${echo}â€ ë©”ëª¨í•´ë‘˜ê²Œ~ ë‹¤ìŒìœ¼ë¡œ ë­ë¶€í„° í•´ë³¼ê¹Œ?`,
    `ì¢‹ì•„! ê·¸ëŸ¼ ë‹¤ìŒì€ ë­ í•´ë³¼ê¹Œ? ê°‘ìžê¸° ê¶ê¸ˆí•œ ê±° ìžˆì–´?`,
  ]);
}

// ---------------------------
// Web Speech (built-in TTS)
// ---------------------------
let voices = [];
let speaking = false;
let selectedVoice = null;
let mouthPulse = 0;
let mouthShape = 'aa';

function scoreVoice(v) {
  const lang = (v.lang || '').toLowerCase();
  const name = (v.name || '').toLowerCase();
  // We can't guarantee a "cute" voice across OSes, so we pick the best
  // available Korean voice, then slightly raise pitch/rate.
  const langScore = lang.startsWith('ko') ? 30 : (lang.startsWith('ja') ? 10 : 0);
  const nameScore = /(heami|sunhi|seoyeon|yuna|kyoko|haruka|yuri|sora|karen|nana|moe|female|woman|girl)/.test(name) ? 3 : 0;
  const localScore = v.localService ? 1 : 0;
  return langScore + nameScore + localScore;
}

function refreshVoices() {
  voices = window.speechSynthesis?.getVoices?.() ?? [];
  selectedVoice = [...voices].sort((a, b) => scoreVoice(b) - scoreVoice(a))[0] || null;
}

function stopSpeaking() {
  if (window.speechSynthesis) {
    window.speechSynthesis.cancel();
  }
  speaking = false;
  mouthPulse = 0;
}

stopBtn.addEventListener('click', stopSpeaking);

function pulseMouth() {
  // Short "open" envelope. We'll decay it in the render loop.
  mouthPulse = Math.min(1, mouthPulse + 0.75);
  mouthShape = pick(['aa', 'ih', 'ou', 'ee', 'oh']);
}

function speak(text) {
  if (!window.speechSynthesis || !window.SpeechSynthesisUtterance) {
    addMessage('bot', 'ì´ ë¸Œë¼ìš°ì €ëŠ” Web Speech TTSë¥¼ ì§€ì›í•˜ì§€ ì•Šì•„â€¦');
    return;
  }

  stopSpeaking();

  const u = new SpeechSynthesisUtterance(text);
  u.voice = selectedVoice || voices[0] || null;
  // Default to a slightly "cute" tone.
  u.pitch = Number(pitchEl.value || 1.35);
  u.rate = Number(rateEl.value || 1.15);

  // Approximate lip sync: boundary events (if supported) + lightweight fallback.
  u.onboundary = () => pulseMouth();

  u.onstart = () => {
    speaking = true;
    // Trigger a cute, natural reaction gesture/expression based on the sentence.
    triggerReactionForText(text, { isBot: true });
  };
  u.onend = () => { speaking = false; mouthPulse = 0; };
  u.onerror = () => { speaking = false; mouthPulse = 0; };

  window.speechSynthesis.speak(u);
}

// Some browsers load voices async
if (window.speechSynthesis) {
  window.speechSynthesis.onvoiceschanged = refreshVoices;
  refreshVoices();
}

// ---------------------------
// Three.js + VRM
// ---------------------------
let currentVrm = null;
let mixer = null;
let idleAction = null;
let currentAction = null;
const vrmaCache = new Map(); // fileName -> AnimationClip

const VRMA_BASE_URL = 'https://raw.githubusercontent.com/tk256ailab/vrm-viewer/main/VRMA/';
const MOTIONS = {
  idle: 'Relax.vrma',
  greeting: 'Goodbye.vrma',
  happy: 'Blush.vrma',
  clap: 'Clapping.vrma',
  sad: 'Sad.vrma',
  surprised: 'Surprised.vrma',
  thinking: 'Thinking.vrma',
  sleepy: 'Sleepy.vrma',
  jump: 'Jump.vrma',
  look: 'LookAround.vrma',
  angry: 'Angry.vrma',
};

const vrmaLoader = new GLTFLoader();
vrmaLoader.register((parser) => new VRMAnimationLoaderPlugin(parser));

function setExpressionSafe(name, v) {
  const em = currentVrm?.expressionManager;
  if (!em) return;
  try {
    em.setValue(name, v);
  } catch {
    // Ignore missing expressions
  }
}

async function loadMotionClip(fileName) {
  if (vrmaCache.has(fileName)) return vrmaCache.get(fileName);
  const gltf = await vrmaLoader.loadAsync(VRMA_BASE_URL + fileName);
  const vrmAnim = gltf.userData.vrmAnimations?.[0];
  if (!vrmAnim) throw new Error('VRMA has no vrmAnimations');
  const clip = createVRMAnimationClip(vrmAnim, currentVrm);
  vrmaCache.set(fileName, clip);
  return clip;
}

async function ensureIdle() {
  if (!currentVrm) return;
  if (!mixer) mixer = new THREE.AnimationMixer(currentVrm.scene);
  if (idleAction) return;
  const clip = await loadMotionClip(MOTIONS.idle);
  idleAction = mixer.clipAction(clip);
  idleAction.setLoop(THREE.LoopRepeat, Infinity);
  idleAction.enabled = true;
  idleAction.play();
  currentAction = idleAction;
}

function crossFadeTo(nextAction, fade = 0.25) {
  if (!nextAction) return;
  if (currentAction && currentAction !== nextAction) {
    nextAction.reset();
    nextAction.enabled = true;
    nextAction.play();
    currentAction.crossFadeTo(nextAction, fade, false);
  } else {
    nextAction.reset();
    nextAction.enabled = true;
    nextAction.play();
  }
  currentAction = nextAction;
}

async function playOneShot(fileName, { fade = 0.2, strength = 1.0 } = {}) {
  if (!currentVrm) return;
  await ensureIdle();
  const clip = await loadMotionClip(fileName);
  const a = mixer.clipAction(clip);
  a.setEffectiveWeight(strength);
  a.setLoop(THREE.LoopOnce, 1);
  a.clampWhenFinished = true;

  // Fade out any non-idle action quickly.
  if (currentAction && currentAction !== idleAction) {
    currentAction.fadeOut(0.12);
  }
  crossFadeTo(a, fade);

  // Return to idle when finished.
  const onFinished = (e) => {
    if (e.action !== a) return;
    mixer.removeEventListener('finished', onFinished);
    if (idleAction) {
      idleAction.reset();
      idleAction.enabled = true;
      idleAction.play();
      a.crossFadeTo(idleAction, 0.25, false);
      currentAction = idleAction;
    }
  };
  mixer.addEventListener('finished', onFinished);
}

function chooseEmotionFromText(text) {
  const t = (text || '').toLowerCase();
  if (/(í”¼ê³¤|ì¡¸ë ¤|ìž |sleep)/.test(t)) return 'sleepy';
  if (/[!ï¼]{1,}/.test(text)) return 'surprised';
  if (/[?ï¼Ÿ]{1,}/.test(text)) return 'thinking';
  if (/(ë¯¸ì•ˆ|sorry|ìŠ¬í”„|íž˜ë“¤|ìš°ìš¸|ì‹«ì–´)/.test(t)) return 'sad';
  if (/(ì§œì¦|í™”ë‚˜|angry)/.test(t)) return 'angry';
  if (/(ã…‹ã…‹|ã…Žã…Ž|lol|ê·€ì—½|ì¢‹ì•„|ìµœê³ )/.test(t)) return 'happy';
  return 'neutral';
}

function triggerReactionForText(text, { isBot = true } = {}) {
  const emo = chooseEmotionFromText(text);
  // Expressions (if the model has them)
  setExpressionSafe('happy', emo === 'happy' ? 0.55 : 0.18);
  setExpressionSafe('sad', emo === 'sad' ? 0.55 : 0.0);
  setExpressionSafe('angry', emo === 'angry' ? 0.45 : 0.0);
  setExpressionSafe('surprised', emo === 'surprised' ? 0.35 : 0.0);
  setExpressionSafe('relaxed', 0.15);

  // After a moment, return to a mild baseline.
  const token = Symbol('expr');
  triggerReactionForText._lastToken = token;
  setTimeout(() => {
    if (triggerReactionForText._lastToken !== token) return;
    setExpressionSafe('sad', 0.0);
    setExpressionSafe('surprised', 0.0);
    // Keep a slight "cute" happy baseline.
    setExpressionSafe('angry', 0.0);
    setExpressionSafe('happy', 0.18);
  }, 1600);
  // Motions (VRMA one-shots). If it fails to load (network blocked), expressions still work.
  const looksLikeGreeting = /^(ì•ˆë…•|ã…Žã…‡|í•˜ì´|hello|hi)\\b/i.test((text || '').trim());
  if (looksLikeGreeting && isBot) {
    playOneShot(MOTIONS.greeting).catch(() => {});
    return;
  }

  const map = {
    happy: () => playOneShot(Math.random() < 0.45 ? MOTIONS.happy : MOTIONS.clap),
    sad: () => playOneShot(MOTIONS.sad),
    surprised: () => playOneShot(MOTIONS.surprised),
    thinking: () => playOneShot(MOTIONS.thinking),
    sleepy: () => playOneShot(MOTIONS.sleepy, { strength: 0.95 }),
    angry: () => playOneShot(MOTIONS.angry, { strength: 0.95 }),
    neutral: () => (Math.random() < 0.22 ? playOneShot(MOTIONS.look, { strength: 0.9 }) : Promise.resolve()),
  };
  (map[emo] || map.neutral)().catch(() => {});
}

// WebGL2 check: three-vrm MToon shaders use GLSL3 features.
// If the device/browser falls back to WebGL1, MToon may fail to compile.
const gl2 = canvas.getContext('webgl2', { antialias: true, alpha: true });
const supportsWebGL2 = !!gl2;
if (!supportsWebGL2) {
  console.warn('[VTuber] WebGL2 not available. Falling back to basic materials (no MToon).');
  addMessage('bot', 'âš ï¸ ì´ ê¸°ê¸°ì—ì„œëŠ” WebGL2ê°€ êº¼ì ¸ìžˆê±°ë‚˜ ì§€ì›ë˜ì§€ ì•Šì•„, ê°„ë‹¨í•œ ìž¬ì§ˆë¡œ í‘œì‹œí• ê²Œ.');
}

const renderer = new THREE.WebGLRenderer({
  canvas,
  context: gl2 || undefined,
  antialias: true,
  alpha: true,
});
renderer.setPixelRatio(Math.min(window.devicePixelRatio, 2));
renderer.setSize(canvas.clientWidth, canvas.clientHeight, false);
renderer.outputColorSpace = THREE.SRGBColorSpace;

const scene = new THREE.Scene();
// Classroom-like background (free photo).
// NOTE: We load from a free CDN-friendly host to keep this repo small.
const BG_URL = 'https://images.pexels.com/photos/289740/pexels-photo-289740.jpeg?auto=compress&cs=tinysrgb&w=1600';
{
  const texLoader = new THREE.TextureLoader();
  texLoader.setCrossOrigin('anonymous');
  texLoader.load(
    BG_URL,
    (tex) => {
      tex.colorSpace = THREE.SRGBColorSpace;
      scene.background = tex;
    },
    undefined,
    () => {
      // fallback
      scene.background = new THREE.Color(0x0b0f14);
    }
  );
}
scene.fog = new THREE.Fog(0x0b0f14, 2.2, 7.0);

const camera = new THREE.PerspectiveCamera(30, 1, 0.1, 100);
camera.position.set(0, 1.35, 2.4);

const controls = new OrbitControls(camera, renderer.domElement);
controls.target.set(0, 1.25, 0);
controls.enableDamping = true;

scene.add(new THREE.HemisphereLight(0xffffff, 0x223344, 1.1));
const dir = new THREE.DirectionalLight(0xffffff, 1.1);
dir.position.set(1.5, 2.5, 2.0);
scene.add(dir);

// Simple floor to ground the avatar.
{
  const g = new THREE.PlaneGeometry(10, 10);
  const m = new THREE.MeshStandardMaterial({ color: 0x0f1722, roughness: 1.0, metalness: 0.0 });
  const floor = new THREE.Mesh(g, m);
  floor.rotation.x = -Math.PI / 2;
  floor.position.y = 0;
  floor.receiveShadow = false;
  scene.add(floor);
}

function cloneBasicMaterial(src, isSkinned) {
  // Replace MToon (custom toon shader) with a standard PBR material to keep WebGL1 compatibility.
  const dst = new THREE.MeshStandardMaterial();
  if (src.color) dst.color.copy(src.color);
  if (src.map) dst.map = src.map;
  if (src.normalMap) dst.normalMap = src.normalMap;
  if (src.emissive) dst.emissive.copy(src.emissive);
  if (src.emissiveMap) dst.emissiveMap = src.emissiveMap;
  if (src.roughness != null) dst.roughness = src.roughness;
  if (src.metalness != null) dst.metalness = src.metalness;

  // Transparency / cutout
  dst.transparent = !!src.transparent;
  dst.opacity = src.opacity != null ? src.opacity : 1;
  dst.alphaTest = src.alphaTest != null ? src.alphaTest : 0;
  dst.depthWrite = src.depthWrite != null ? src.depthWrite : true;
  dst.side = src.side != null ? src.side : THREE.FrontSide;

  // Skinning
  dst.skinning = !!isSkinned;

  dst.needsUpdate = true;
  return dst;
}

function downgradeMaterialsForWebGL1(root) {
  root.traverse((obj) => {
    if (!obj.isMesh) return;
    const isSkinned = !!obj.isSkinnedMesh;
    const mats = Array.isArray(obj.material) ? obj.material : [obj.material];
    const newMats = mats.map((m) => {
      if (!m) return m;
      // Avoid cloning if it's already a standard material
      const type = (m.type || '').toLowerCase();
      if (type.includes('standard') || type.includes('phong') || type.includes('lambert')) {
        if (isSkinned && m.skinning !== true) {
          m.skinning = true;
          m.needsUpdate = true;
        }
        return m;
      }
      return cloneBasicMaterial(m, isSkinned);
    });
    obj.material = Array.isArray(obj.material) ? newMats : newMats[0];
  });
}

const loader = new GLTFLoader();
loader.register((parser) => new VRMLoaderPlugin(parser));

async function loadVrm() {
  addMessage('bot', 'ì•„ë°”íƒ€ ë¡œë”©ì¤‘â€¦');
  return new Promise((resolve, reject) => {
    loader.load(
      './assets/Base_Female.vrm',
      (gltf) => {
        const vrm = gltf.userData.vrm;
        VRMUtils.removeUnnecessaryVertices(gltf.scene);
        VRMUtils.removeUnnecessaryJoints(gltf.scene);

        if (currentVrm) {
          scene.remove(currentVrm.scene);
        }
        currentVrm = vrm;

        if (!supportsWebGL2) {
          // Make the avatar visible on WebGL1 by replacing MToon materials.
          downgradeMaterialsForWebGL1(vrm.scene);
        }


        // Nice default pose/position
        vrm.scene.rotation.y = Math.PI; // face camera
        scene.add(vrm.scene);

        // Slightly â€œcuteâ€ expression baseline
        setExpressionSafe('happy', 0.18);
        setExpressionSafe('relaxed', 0.15);

        // Start the default idle VRMA motion to avoid T-pose.
        ensureIdle()
          .then(() => {
            // Preload a few common one-shots in the background (best effort).
            [MOTIONS.greeting, MOTIONS.happy, MOTIONS.thinking, MOTIONS.surprised].forEach((m) => {
              loadMotionClip(m).catch(() => {});
            });
          })
          .catch(() => {
            // If VRMA fails to load (offline/CORS), we still show the model.
          });

        addMessage('bot', 'ë¡œë”© ì™„ë£Œ! (êµì‹¤ ë°°ê²½ + ê¸°ë³¸ ëª¨ì…˜ ì ìš©)');
        resolve(vrm);
      },
      undefined,
      (err) => {
        console.error(err);
        addMessage('bot', 'ì•„ë°”íƒ€ ë¡œë”©ì— ì‹¤íŒ¨í–ˆì–´â€¦');
        reject(err);
      }
    );
  });
}

const VISEMES = ['aa', 'ih', 'ou', 'ee', 'oh'];
function setMouthShape(shape, amount) {
  const em = currentVrm?.expressionManager;
  if (!em) return;
  for (const k of VISEMES) {
    em.setValue(k, k === shape ? amount : 0);
  }
}

function resize() {
  const w = canvas.clientWidth;
  const h = canvas.clientHeight;
  renderer.setSize(w, h, false);
  camera.aspect = w / h;
  camera.updateProjectionMatrix();
}

window.addEventListener('resize', resize);

let last = performance.now();
let blinkCooldown = 1.8 + Math.random() * 2.8;
let blinkPhase = 0; // 0 = idle, >0 = blinking seconds

function updateBlink(dt) {
  if (!currentVrm) return;

  if (blinkPhase > 0) {
    blinkPhase += dt;
    // A quick smooth blink
    const dur = 0.12;
    const x = Math.min(1, blinkPhase / dur);
    const v = Math.sin(x * Math.PI); // 0->1->0
    setExpressionSafe('blink', v);
    if (blinkPhase >= dur) {
      blinkPhase = 0;
      setExpressionSafe('blink', 0);
      blinkCooldown = 1.6 + Math.random() * 3.6;
    }
    return;
  }

  blinkCooldown -= dt;
  if (blinkCooldown <= 0) {
    blinkPhase = 0.0001;
  }
}

function tick(now) {
  const dt = (now - last) / 1000;
  last = now;

  resize();
  controls.update();

  if (currentVrm) {
    // Animations
    mixer?.update(dt);
    currentVrm.update(dt);

    // Blink
    updateBlink(dt);

    // Lip sync (very rough): decay the pulse, and occasionally pulse while speaking.
    if (speaking && mouthPulse < 0.15 && Math.random() < dt * 10) pulseMouth();
    mouthPulse = Math.max(0, mouthPulse - dt * 5.5);
    setMouthShape(mouthShape, mouthPulse * 0.85);
  }

  renderer.render(scene, camera);
  requestAnimationFrame(tick);
}

await loadVrm();

// Seed a few random greeting lines so you can immediately see reactions.
{
  const greet = pick([
    'ì•ˆë…•~ ì˜¤ëŠ˜ë„ ë§Œë‚˜ì„œ ë°˜ê°€ì›Œ! ðŸ˜Š',
    'í•˜ì´í•˜ì´! êµì‹¤ì— ë†€ëŸ¬ì™”ì–´? âœ¨',
    'ì•ˆë‡½! ë­ ì–˜ê¸°í•´ë³¼ê¹Œ? ðŸ˜³',
  ]);
  addMessage('bot', greet);
  // Don't auto-speak immediately (some people hate autoplay). Click Send to hear.
  addMessage('bot', 'ì˜ˆì‹œ: "ì•ˆë…•" / "ì˜¤ëŠ˜ ë­í•´?" / "ã…‹ã…‹" / "í”¼ê³¤í•´" ê°™ì€ ë§ë„ ì¢‹ì•„!');
  triggerReactionForText(greet, { isBot: true });
}
requestAnimationFrame(tick);

// ---------------------------
// Chat flow
// ---------------------------
form.addEventListener('submit', (e) => {
  e.preventDefault();
  const text = msgInput.value.trim();
  if (!text) return;
  msgInput.value = '';

  addMessage('user', text);
  // A small acknowledgement gesture when you talk to her.
  triggerReactionForText(text, { isBot: false });
  const reply = makeReply(text);

  // Give a tiny delay for â€œchat-likeâ€ feel
  setTimeout(() => {
    addMessage('bot', reply);
    speak(reply);
  }, 250);
});
